---
layout: post
title:  "浅谈“人工智能”"
date:   2017-05-20 16:22:49 +0800
categories: jekyll update
---

![](https://ss0.bdstatic.com/94oJfD_bAAcT8t7mm9GUKT-xh_/timg?image&quality=100&size=b4000_4000&sec=1495698545&di=e5b7a03ab72a22a29834f3091784b5ae&src=http://www.enicn.com/uploadfile/2016/1122/20161122120444698.jpg)

## 摘要:

` 关键字：人工智能、深度学习、信息化社会、智能机器  、机器学习、人工神经网络、危险论 `


前言：我们正站在变革的边缘，而这次变革将和人类的出现一样意义重大。现在我们正处于科技飞速发展，以及信息爆炸的时代，原来越多曾经难以实现的技术，都在逐渐出现在人们视野。这篇文章将会介绍“人工智能”这项先进的技术，关于它的定义、技术实现、和发展前景。




### 人工智能 是什么？

在定义人工智能以前，得先说说自然智能。地球上的两大难题是宇宙起源和人脑奥秘，说明现代科学家们对人脑奥秘知之甚少。的确，人脑实在是太精细和复杂了，人脑结构中含有千亿－万亿个神经元，而且呈并行分布；大脑的功能有：记忆、思维、观察、分析、学习等。那么人工智能又是什么呢？
关于人工智能现在还众说纷纭，目前没有统一的定义，一般解释是用人工的方法在机器或计算机上实现的智能。我的理解是，人工智能是让计算机像人一样思考的技术，尽力实现让机器模拟人类的大脑水平，是对人的意识、思维的信息过程的模拟。它能让机器在各类环境中自主地或交互地执行各种拟人任务。说起来有些不可思议，代码、算法和机器都是由人创造的，那么人工智能怎能做到像人一样思考和反应呢？
“人工智能”一词，从字面上可拆分，事实上它的定义也可以分为两部分。第一部分是“人工”，顾名思义。便是让机器代替人力，做一些繁琐和精细的工作。“智能”这一部分就较难定义了，涉及到其他诸如意识和思维等等问题，因为人类所了解的智能是人本身的智能，但关于机器，按照艾伦图灵的定义是：如果一台机器能够通过电传设备与人类展开对话，而不能被辨认出其机器身份，那么称这台机器具有智能。二十一世纪以来我们对“智能”的要求更高，想到“人工智能”，会首先想到科幻电影里能自主思考和判断的超级助手。实现“智能”的一个难处在于：就连我们也对自己本身智能的理解不够。基于这种有限的了解，其他关于动物或者其他人工系统的智能也算作是与人工智能相关的研究项目。
人工智能有不同的定义。从能力上的定义是：智能机器所执行的通常是与人类智能有关的智力行为，比如思考、判断、感知、推理、学习和问题求解等思维活动。从学科上定义是计算机科学中涉及研究、设计和应用智能机器的一个分支。它用于研究用机器模仿且执行某些人脑的功能，并开发相关理论和技术。


### 人工智能发展史

人类梦想着发明各种机械工具和动力机器，协助甚至代替人们从事各种体力劳动。十八世纪第一次工业革命中，瓦特发明的蒸汽机开辟了利用机器动力代替人力和畜力的新纪元。此后，大幅度减轻体力劳动和实现生产过程自动化才成为可能。
人类同样梦想发明各种智能工具和智能机器，协助甚至代替人们从事各种脑力劳动。二十世纪四十年代计算机的发明和五十年代人工智能的出现开辟了利用智能机器代替人类从事脑力劳动的新纪元。此后，显著减轻脑力劳动和实现生产过程智能化才成为可能。
与人工智能相关的传说可以追溯到古埃及，但1941年以来随着电子计算机的发展，技术早已能创造出智能机器。暂时将发展史分为孕育期、形成期、暗淡期、知识应用期、集成发展期。
孕育期即是指1956年以前提出的关于人工智能的思想与算法，是人工智能的起源与发展。古希腊伟大的哲学家和思想家亚里士多德，，创立了演绎法，他提出了三段论，至今仍然是演绎推理的出发点。德国数学家和哲学家莱布尼茨奠定了数理逻辑的基础，即把形式逻辑符号化。英国数学家图灵，1936年创立了自动机理论，也就是图灵机理论。在1950年著名的图灵测试诞生了，在他1950年的著作《计算机器与智能》中首次提出“机器也能思维”的理论，他在计算机相关专业人士之间家喻户晓，被誉为是“人工智能之父”。美国数学家、电子数字计算机的先驱莫克在1946年成功研制了世界上第一台通用电子数字计算机ENIAC。美国神经生理学家麦克洛奇和皮兹于1943年建成了第一个神经网络模型。美国著名数学家、控制论创始人维纳，他创立的控制论对人工智能的影响形成了行为主义学派。
1956年至1970年则是形成期，首先就是一次历史性的聚会——达特茅斯会议。这是一次在美国达特茅斯大学举办的、长达两个多月的研讨会，众多学者热切地讨论用机器模拟人类智能的问题。在这次会议上，“人工智能”这个术语由四位图灵奖得主信息论创始人和一位诺贝尔奖得主提出，这标志着人工智能作为一门学科的诞生，也是人类历史上第一次人工智能研讨会，因此具有相当重要的历史意义。值得一提的是，第二年的达特茅斯研讨会上，关于人工智能有两派观点。于是主持人最后总结说：“（一派人）企图模拟神经系统，而另一方则企图模拟心智…但最终将殊途同归。” 这句话预示了人工智能之后几十年关于“结构与功能”的斗争。
在此后的几十年里，人们产生了许多对人工智能的奇思妙想，研究人员也投入全身心于研究。人工智能一度被捧为开启人类光明未来的大门的钥匙，后来又被当做是自大的异想天开。但在过去的几年里，人工智能开始出现爆炸式发展，尤其是在2015年以后。究其原因，主要是图形处理器GPU的广泛应用，使得并行处理更快更强大。此外，还得益于几乎无限的存储空间和大数据运动的出现：图像、文本、交易数据、地图数据应有尽有。 



### 人工智能的发展和应用

对于我们大多数人来说，提起人工智能，第一反应是想到《星球大战》、《终结者》、《复仇者联盟2：奥创纪元》等电影。由于电影都是相对虚构的，所以带给我们关于人工智能虚幻而不真实的印象。但事实上，人工智能已经是已经存在的事实，我们日常生活中就在每天使用它了，只是我们没意识到。比如我们用的苹果手机里的语音助手Siri就是人工智能的人格化体现，还有人工智能下的机器学习：Apple Magic Mouse、Trackpad和指纹识别等等。大多数人受电影或科幻小说的影响，总是把人工智能和机器人联系在一起，认为人工智能一定体现在“具有自己意识”的机器人上。这种看法是相对狭隘的，如果把人工智能比作人类的大脑，那么机器人就类似于人类的身体，不同的是，这个身体不一定是必须的，即机器人相对来说只是人工智能技术的一个不必须的容器罢了。
人工智能是个较广的概念，所以理所当然的人工智能分为很多种，按实力分成下面三大类：
弱人工智能Artificial Narrow Intelligence(ANI)、强人工智能Artificial General Intelligence(AGI)和超人工智能Artificial Super Intelligence(ASI)。
弱人工智能是只在某个方面擅长的人工智能，比如会下围棋的AlphaGo。强人工智能相当于人类级别的人工智能，能够进行思考、计划、解决问题、快速学习和从错误和经验中学习等操作，是各方面都能与人类比肩的级别。人类能从事的脑力活动都能交给它，因此实现强人工智能比实现弱人工智能困难许多，现在的技术还不能做到。顾名思义，超人工智能是比强人工智能更上一层台阶的技术，知名人工智能思想家Nick Bostrom把超人工智能定义为“几乎在所有领域都比最聪明的人类大脑聪明许多，包括科学创新、通识和社交技能。”我们常看到的科幻电影和小说里面的全能智能助手就属于超人工智能。
目前人类已经掌握了弱人工智能，我们处于充满了弱人工智能的世界，一些寻常的例子有：

－汽车上有很多的弱人工智能系统，从控制防抱死系统的电脑，到控制汽油注入参数的电脑。谷歌正在测试的无人驾驶车，就包括了很多弱人工智能，这些弱人工智能可以通过感知周围环境而作出反应。
－你的手机也充满了弱人工智能系统。当你用地图软件导航，接受音乐电台推荐，查询明天的天气，和Siri聊天，指纹识别，以及其它很多很多应用，其实都是弱人工智能。
－你使用的邮箱有垃圾文件过滤选项，其中的垃圾邮件过滤器是一种经典的弱人工智能——它一开始就加载了很多识别垃圾邮件的智能，并且它会学习并且根据你的使用而获得经验。智能室温调节也是一样，它能根据记录你的日常习惯来智能调节。
－你在上网时候出现的各种其它电商网站的产品推荐，还有社交网站的好友推荐，这些都是弱人工智能的组成的，弱人工智能联网互相沟通，利用你的信息来进行推荐。在淘宝网上网购时出现的“买这个商品的人还购买了”推荐，其实就是弱人工智能的实现：收集数百万用户行为然后产生信息来卖东西给你。
－谷歌翻译也是一种经典的人工智能——非常擅长单个领域。声音识别也是一种。很多软件利用这两种智能的合作，使得你能对着手机说中文，手机直接给你翻译成英文。
－当飞机着陆时候，不是一个人类决定飞机该去那个登机口接驳。就好像在网上买票时票据不是一个人类决定的。
－世界最强的跳棋、象棋、拼字棋、双陆棋和黑白棋选手都是弱人工智能。
－各大搜索引擎搜索是一个巨大的弱人工智能，背后是非常复杂的排序方法和内容检索。社交网络的新鲜事同样是这样。
这些还只是消费级产品的例子。制造、军事、金融、城市管理等领域广泛运用各种复杂的弱人工智能。专业系统也有，比如帮助医生诊断疾病的系统，还有著名的IBM的华生，储存了大量事实数据，还能理解主持人的提问，在竞猜节目中能够战胜最厉害的参赛者。
现在的弱人工智能系统并没有发展到惊人的地步。最糟糕的情况，无非是算法有问题，代码没写完整，程序出故障，造成了单独的灾难，比如造成停电、核电站故障、金融市场崩盘等等。
但从弱人工智能到强人工智能之路，这条路很难走。当明白创造一个人类智能水平的电脑是多么不容易，才能真的理解人类的智能是多么不可思议。造金字塔、制造飞向太空的火箭、明白宇宙大爆炸的细节——这些都比理解人类的大脑，并且创造个类似的东西要简单太多了。至今为止，人类的大脑是我们所知宇宙中最复杂的东西。而且创造强人工智能的难处，并不是我们本能认为的那些。
比如：
造一个能在瞬间算出十位数乘法的计算机非常简单；
造一个能分辨出一个动物是猫还是狗的计算机极端困难；
造一个能战胜世界象棋冠军的电脑，早已成功；
造一个能够读懂六岁小朋友的图片书中的文字，并且了解那些词汇意思的电脑——谷歌花了几十亿美元在做，还没做出来。
微积分、金融市场策略、翻译等这些对于普通人来说困难的事，对于电脑来说都太简单了。然而我们觉得容易的事情——视觉、动态、移动、直觉、思考，这些对于电脑来说太难了。那些对我们来说很简单的事情，其实是很复杂的，它们看上去很简单，因为它们已经在动物进化的过程中经历了几亿年的优化了。当你举手拿一件东西的时候，你肩膀、手肘、手腕里的肌肉、神经和骨头，瞬间就进行了一组复杂的物理运作，这一切还配合着你的眼睛的运作，使得你的手能都在三维空间中进行直线运作。对你来说这一切轻而易举，因为在你脑中负责处理这些的“软件”已经很完美了。同样的，软件很难识别网站的验证码，不是因为软件太蠢，恰恰相反，是因为能够读懂验证码是件很厉害、长期发展得到的技能。
同样的，大数相乘、下棋等等，对于生物来说是很新的技能，我们还没有几亿年的世界来进化这些能力，所以电脑很轻易的就击败了我们。试想一下，如果要求写一个程序，是一个能实现加减乘除的程序容易写，还是能够识别人种和判断性格的程序难写？
用计算机科学家Donald Knuth的说法，“人工智能已经在几乎所有需要思考的领域超过了人类，但是在那些人类和其它动物不需要思考就能完成的事情上，还差得很远。”
所以要想达到人类的智能，电脑需要理解更高深的东西，比如分辨一些情绪和面部表情变化，以及为什么这本书和这本电影是好作品，而那本书和那个电影是很差的作品。
至于如何从弱人工智能走向强人工智能，是现在的热门研究内容。专家认为通往强人工智能可分为两步步，第一步是增加电脑处理速度，即电脑的运行能力要达到人脑的水平。现在世界上最快的超级计算机，中国的天河二号已经超过人类的计算能力了。第二步是让电脑变的智能。
下面是三种主流的、可能有效的策略：
#### 1.抄袭人脑
就像抄袭身边学霸的答案从而考试得高分，”这种“抄袭”是具有可行性的，我们想要建造一个超级复杂的电脑，可以参考人脑这个范本。科学界正在努力逆向工程人脑，一旦理解生物进化是怎么造出人脑这个复杂系统的目标达成，我们就能知道为什么人脑能够如此有效、迅速的运行，并且能从中获得灵感来进行创新。人工神经网络就是一个电脑架构模拟人脑的例子。
#### 2.模仿生物演化
即用模拟演化的方式来造强人工智能，这种方法叫作“基因算法”。
#### 3.让电脑来解决这些问题
思路是我们建造一个能进行两项任务的电脑——研究人工智能和修改自己的代码。这样它就不只能改进自己的架构了，电脑直接变成了电脑科学家，提高电脑的智能就变成了电脑自己的任务。
以上这些可能都会很快发生，硬件的快速发展和软件的创新是相辅相成的，强人工智能可能比我们预期的更早降临。

在我们可见的关于人工智能的未来，我认为预见的画面是欣欣向荣的。李开复作为AI辅助投资的参与者、AI辅助治疗的受益者和AI企业的投资者，在某综艺上谈了自己的经历和对人工智能的前景看法，使观众们了解到人工智能的魅力和价值所在。他表示：十年内重复性的工作将被彻底代替，娱乐、美丑和幽默区分是人工智能最大短板。这就说明了至少在可见的未来，在艺术等方面人类还是不可被人工智能所替代的。

### 人工智能、机器学习和深度学习

人工智能是个相对广泛的概念，想要深入一些地了解它，就必须讲到机器学习和深度学习。我们知道，目前强人工智能（通用人工智能）尚未只存在于电影和科幻小说中，我们力所能及的是弱人工智能。那么弱人工智能又是如何实现的呢？智能来自何处呢？就涉及到从属于人能智能这个大概念的机器学习。
机器学习是实现人工智能的一种方法。它的概念来自早期的人工智能研究者，中文维基百科给出的机器学习的定义是：“机器学习是近20多年兴起的一门多领域交叉学科，涉及概率论、统计学、逼近论、凸分析、算法复杂度理论等多门学科。机器学习理论主要是设计和分析一些让计算机可以自动“学习”的算法。机器学习算法是一类从数据中自动分析获得规律，并利用规律对未知数据进行预测的算法。因为学习算法中涉及了大量的统计学理论，机器学习与统计推断学联系尤为密切，也被称为统计学习理论。算法设计方面，机器学习理论关注可以实现的，行之有效的学习算法。很多推论问题属于无程序可循难度，所以部分的机器学习研究是开发容易处理的近似算法。”目前的传统算法包括决策树学习、归纳逻辑编程、增强学习和贝叶斯网络等等。机器学习最基本的做法，是使用算法来解析数据、从中学习，然后对真实世界中的事件做出决策和预测，核心在于用大量的数据来“训练”电脑，从而通过各种算法从数据中学习如何完成任务。目前机器学习最成功的应用领域是计算机视觉。
提到机器学习，就不得不说到深度学习——一种实现机器学习的技术。深度学习的概念由Hinton等人于2006年提出，是源于人工神经网络的研究。含多隐层的多层感知器就是一种深度学习结构。深度学习通过组合低层特征形成更加抽象的高层表示属性类别或特征，以发现数据的分布式特征表示。
深度学习是机器学习研究中的一个新的领域，是实现机器学习的一种技术。基本特点是试图模仿大脑的神经元之间传递、处理信息的模式，其动机在于建立、模拟人脑进行分析学习的神经网络，它模仿人脑的机制来解释数据，例如图像，声音和文本。深度机器学习方法有监督学习与无监督学习之分．不同的学习框架下建立的学习模型很是不同．例如，卷积神经网络（Convolutional neural networks，简称CNNs）就是一种深度的监督学习下的机器学习模型，而深度置信网（Deep Belief Nets，简称DBNs）就是一种无监督学习下的机器学习模型。
早期机器学习研究者开发了一种叫人工神经网络的算法，这是受人类大脑神经元之间的相互连接关系的的启发而来的。人类大脑中的神经元可以与特定范围内的任意神经元连接，但人工神经网络中的数据传输要经历不同的层次，传播方向也不同。每个神经元都会给其输入指定一个权重：相对于执行的任务该神经元的正确和错误程度。最终的输出由这些权重共同决定。
毫无疑问机器学习是当前数据分析领域的热门话题，其算法有很多，接下来介绍机器学习的学习方式和类似的算法。
解决问题时常常需要根据不同的数据类型对问题建模，然而建模也有多种方式。在机器学习和人工智能领域，我们会首先考虑算法的学习方式。有这样几种主要的学习方式：监督学习、非监督学习、半监督学习和强化学习。
1.监督式学习：
在监督式学习下，输入的数据被称为“训练数据”，每组训练数据有一个明确的标识或结果，如对防垃圾邮件系统中“垃圾邮件”“非垃圾邮件”，对性别的识别等。在建立预测模型的时候，监督式学习建立一个学习过程，将预测结果与“训练数据”的实际结果进行比较，不断的调整预测模型，直到模型的预测结果达到一个预期的准确率。分类问题和回归问题是监督式学习的常见应用场景。常见监督式学习算法有决策树学习，朴素贝叶斯分类，最小二乘回归，逻辑回归，支撑矢量机，集成方法以及反向传递神经网络等等。
2、非监督式学习：

       在非监督式学习中，数据并不被特别标识，学习模型是为了推断出数据的一些内在结构。常见的应用场景包括关联规则的学习以及聚类等。常见非监督学习算法包括奇异值分解、主成分分析，独立成分分析，Apriori算法以及k-Means算法等等。

3、半监督式学习：

       在此学习方式下，输入数据部分被标识，部分没有被标识，这种学习模型可以用来进行预测，但是模型首先需要学习数据的内在结构以便合理的组织数据来进行预测。应用场景包括分类和回归，算法包括一些对常用监督式学习算法的延伸，这些算法首先试图对未标识数据进行建模，在此基础上再对标识的数据进行预测。如图论推理算法（Graph Inference）或者拉普拉斯支持向量机（Laplacian SVM）等。

4、强化学习：

       在这种学习模式下，输入数据作为对模型的反馈，不像监督模型那样，输入数据仅仅是作为一个检查模型对错的方式，在强化学习下，输入数据直接反馈到模型，模型必须对此立刻作出调整。常见的应用场景包括动态系统以及机器人控制等。常见算法包括Q-Learning以及时间差学习（Temporal difference learning）。在企业数据应用的场景下， 人们最常用的可能就是监督式学习和非监督式学习的模型。 在图像识别等领域，由于存在大量的非标识的数据和少量的可标识数据， 目前半监督式学习是一个很热的话题。 而强化学习更多的应用在机器人控制及其他需要进行系统控制的领域。

二、算法类似性
       根据算法的功能和形式的类似性，我们可以把算法分类，比如说基于树的算法，基于神经网络的算法等等。当然，机器学习的范围非常庞大，有些算法很难明确归类到某一类。而对于有些分类来说，同一分类的算法可以针对不同类型的问题。这里，我们尽量把常用的算法按照最容易理解的方式进行分类。


1、回归算法：




       回归算法是试图采用对误差的衡量来探索变量之间的关系的一类算法。回归算法是统计机器学习的利器。在机器学习领域，人们说起回归，有时候是指一类问题，有时候是指一类算法，这一点常常会使初学者有所困惑。常见的回归算法包括：最小二乘法（Ordinary Least Square），逻辑回归（Logistic Regression），逐步式回归（Stepwise Regression），多元自适应回归样条（Multivariate Adaptive Regression Splines）以及本地散点平滑估计（Locally Estimated Scatterplot Smoothing）。

       通常，回归可以被用于在现实世界的应用，如：
·	信用评分
·	度量营销活动的成功率
·	预测某一产品的收入
·	在一个特定的日子里会发生地震吗？
2、基于实例的算法
 

       基于实例的算法常常用来对决策问题建立模型，这样的模型常常先选取一批样本数据，然后根据某些近似性把新数据与样本数据进行比较。通过这种方式来寻找最佳的匹配。因此，基于实例的算法常常也被称为“赢家通吃”学习或者“基于记忆的学习”。常见的算法包括 k-Nearest Neighbor(KNN), 学习矢量量化（Learning Vector Quantization， LVQ），以及自组织映射算法（Self-Organizing Map ， SOM）。
3、正则化方法

       正则化方法是其他算法（通常是回归算法）的延伸，根据算法的复杂度对算法进行调整。正则化方法通常对简单模型予以奖励而对复杂算法予以惩罚。常见的算法包括：Ridge Regression， Least Absolute Shrinkage and Selection Operator（LASSO），以及弹性网络（Elastic Net）。
4、决策树学习

       决策树算法根据数据的属性采用树状结构建立决策模型， 决策树模型常常用来解决分类和回归问题。常见的算法包括：分类及回归树（Classification And Regression Tree， CART）， ID3 (Iterative Dichotomiser 3)， C4.5， Chi-squared Automatic Interaction Detection(CHAID), Decision Stump, 随机森林（Random Forest）， 多元自适应回归样条（MARS）以及梯度推进机（Gradient Boosting Machine， GBM）。
5、贝叶斯方法

       贝叶斯方法算法是基于贝叶斯定理的一类算法，主要用来解决分类和回归问题。常见算法包括：朴素贝叶斯算法，平均单依赖估计（Averaged One-Dependence Estimators， AODE），以及Bayesian Belief Network（BBN）。

       一些现实中的例子：
·	标记一个电子邮件为垃圾邮件或非垃圾邮件
·	将新闻文章分为技术类、政治类或体育类
·	检查一段文字表达积极的情绪，或消极的情绪？
·	用于人脸识别软件
6、基于核的算法
 

       基于核的算法中最著名的莫过于支持向量机（SVM）了。 基于核的算法把输入数据映射到一个高阶的向量空间， 在这些高阶向量空间里， 有些分类或者回归问题能够更容易的解决。 常见的基于核的算法包括：支持向量机（Support Vector Machine， SVM）， 径向基函数（Radial Basis Function ，RBF)， 以及线性判别分析（Linear Discriminate Analysis ，LDA)等。
       就规模而言，其中一些最主要的问题已经使用支持向量机解决了（通过适当的修改），如，入广告显示，人类的剪接位点识别，基于图像的性别检测，大规模图像分类等等。
7、聚类算法
 

       聚类，就像回归一样，有时候人们描述的是一类问题，有时候描述的是一类算法。聚类算法通常按照中心点或者分层的方式对输入数据进行归并。所以的聚类算法都试图找到数据的内在结构，以便按照最大的共同点将数据进行归类。常见的聚类算法包括 k-Means算法以及期望最大化算法（Expectation Maximization， EM）。


每一种聚类算法都不太一样，这里有一些：
·	基于质心的算法
·	基于连通性的算法
·	基于密度的算法
·	概率聚类
·	降维
·	神经网络/深度学习

8、关联规则学习
 

       关联规则学习通过寻找最能够解释数据变量之间关系的规则，来找出大量多元数据集中有用的关联规则。常见算法包括 Apriori算法和Eclat算法等。
9、人工神经网络

 
       人工神经网络算法模拟生物神经网络，是一类模式匹配算法。通常用于解决分类和回归问题。人工神经网络是机器学习的一个庞大的分支，有几百种不同的算法。（其中深度学习就是其中的一类算法，我们会单独讨论），重要的人工神经网络算法包括：感知器神经网络（Perceptron Neural Network）, 反向传递（Back Propagation）， Hopfield网络，自组织映射（Self-Organizing Map, SOM）。学习矢量量化（Learning Vector Quantization， LVQ）。
10、深度学习
 

       深度学习算法是对人工神经网络的发展。 在近期赢得了很多关注， 特别是百度也开始发力深度学习后， 更是在国内引起了很多关注。   在计算能力变得日益廉价的今天，深度学习试图建立大得多也复杂得多的神经网络。很多深度学习的算法是半监督式学习算法，用来处理存在少量未标识数据的大数据集。常见的深度学习算法包括：受限波尔兹曼机（Restricted Boltzmann Machine， RBN）， Deep Belief Networks（DBN），卷积网络（Convolutional Network）, 堆栈式自动编码器（Stacked Auto-encoders）。
11、降低维度算法
 

       像聚类算法一样，降低维度算法试图分析数据的内在结构，不过降低维度算法是以非监督学习的方式试图利用较少的信息来归纳或者解释数据。这类算法可以用于高维数据的可视化或者用来简化数据以便监督式学习使用。常见的算法包括：主成份分析（Principle Component Analysis， PCA），偏最小二乘回归（Partial Least Square Regression，PLS）， Sammon映射，多维尺度（Multi-Dimensional Scaling, MDS）,  投影追踪（Projection Pursuit）等。

       其中，ICA 和 PCA 是相关的，但是它是一种更强大的技术，当那些经典的方法完全失效的时候，它能够从数据源中发现潜在的因素。它的应用包括数字图像，文档数据库，经济指标和心理测量。
12、集成算法：

       集成算法用一些相对较弱的学习模型独立地就同样的样本进行训练，然后把结果整合起来进行整体预测。集成算法的主要难点在于究竟集成哪些独立的较弱的学习模型以及如何把学习结果整合起来。这是一类非常强大的算法，同时也非常流行。常见的算法包括：Boosting， Bootstrapped Aggregation（Bagging）， AdaBoost，堆叠泛化（Stacked Generalization， Blending），梯度推进机（Gradient Boosting Machine, GBM），随机森林（Random Forest）。

那么集成方法是怎样工作的，为什么他们会优于单个的模型？
·	他们拉平了输出偏差：如果你将具有民主党倾向的民意调查和具有共和党倾向的民意调查取平均，你将得到一个中和的没有倾向一方的结果。
·	它们减小了方差：一堆模型的聚合结果和单一模型的结果相比具有更少的噪声。在金融领域，这被称为多元化——多只股票的混合投资要比一只股票变化更小。这就是为什么数据点越多你的模型会越好，而不是数据点越少越好。
·	它们不太可能产生过拟合：如果你有一个单独的没有过拟合的模型，你是用一种简单的方式（平均，加权平均，逻辑回归）将这些预测结果结合起来，然后就没有产生过拟合的空间了。
人工智能的核心在于智能，机器学习则是部署支持人工智能的计算方法。人工智能就像科学，机器学习是让机器变得更加智能的算法，从某种程度上讲，机器学习成就了人工智能。



### 关于人工智能的担忧——“人工智能毁灭人类论”

自从AlphaGo一站成名以后，人工智能成了全世界最热门的话题。由于人类对机器人“不信任感”担心使用机器人带来失业的恐惧，担心“机器人的智能将要超过人类，从而反客为主，要通知人类”，给人类造成了心理威胁。人工智能一向是科幻大片逃不过的题材，喜欢看美国大片的人一定知道漫威公司，以及漫威系列的英雄电影。在电影《复仇者联盟2：奥创纪元》中，就讲了一个关于人工智能的故事。这部电影里，天赋异禀的超级英雄们疲倦于平息动乱，并产生了职业倦怠，为了减少不必要的工作，聪明而富有且精通电脑技术的钢铁侠创造了“奥创”——一个具有自我意识、有学习能力的人工智能机器人，并让它指挥机器人军团。奥创的程序具有自我完善的能力，并逐渐演化变得越来越狡猾和聪明。始料未及的是，奥创不断进化，并得出“人类是地球上最大的威胁”这个结论，进而开始实施毁灭全部人类的清洗计划。超级英雄们不得不再次聚集，解决这个由他们亲手创造的危机。电影的结局不出意外，是奥创被毁灭，但相信在观影途中，大家都会震惊于机器人奥创强大的思维能力，看完以后不禁思考起了这部科幻片意外的问题：未来人工智能真的能达到甚至超越人脑水平吗？如果达到了，它们会违抗人类吗？人类会因此付出代价吗？
人工智能是解放人类还是毁灭人类？这是目前业内最热门的讨论话题之一。
世界著名物理学家霍金持“人工智能威胁论”，多次发出“人工智能或将毁灭人类”的威胁，并表示人工智能的崛起可能是人类文明的终结。他肯定了人工智能给人类带来的积极益处，尤其是可能消除贫困和疾病，甚至有望修复人类对自然世界造成的一些伤害，但不确定最终人工智能会帮到人类，还是会毁灭人类。霍金表示：“文明所产生的一切都是人工智能的产物，我相信生物大脑可以达到的和计算机可以达到的，没有本质区别。因此，它遵循了计算机在理论上可以模仿人工智能，然后超越这一原则。但我们并不确定，所以我们无法知道我们将无限得到人工智能的帮助，还是被藐视并被边缘化，或者很可能被它毁灭。”不仅仅霍金，还有很多比如比尔盖茨、马斯克的名人，让人们警惕人工智能。并表示：人工智能很可能导致人类的永生或者灭绝，而这一切很可能在我们的有生之年发生。
当未来有一天人工智能发展到强人工智能，甚至超人工智能，智能爆炸可能也就不远了。试想一个画面，电影和科幻小说所描述的、或没来得及描述的智能助手甚至AI怪兽出现在我们的日常生活中——那是多么震惊的画面啊！
但另一些人认为人工智能在未来的很长一段时间内是安全的，他们表示人脑的复杂度远远高于电脑，人工智能是无法在某些区域代替人类的，尤其是创造性和艺术性方面。因为结构的不同，人脑的运算方式从本质上和电脑是不一样的，电脑不会发育，也没有可塑性这一说，电脑本身理解语言的意思，它只是会对语言做出识别、甚至反应。“人工智能不是生命现象，而是一种人为的机械模仿”。
百度公司董事长兼CEO李彦宏则表示自己对人工智能的未来很乐观，“至少在我有生之年，人工智能无法毁灭人类。”






《一文读懂人工智能的前世今生》网易科技频道
《人工智能的起源与三次发展浪潮》数智网
《人工智能》百度百科定义
《机器学习》百度百科定义